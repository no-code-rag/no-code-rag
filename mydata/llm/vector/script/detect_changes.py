#!/usr/bin/env python3
import json
from pathlib import Path
from uid_utils import read_jsonl, write_jsonl_atomic_sync

# === ãƒ‘ã‚¹è¨­å®š ===
ROOT = Path("/mydata/llm/vector")
LOG_ROOT = ROOT / "db/log"

SNAPSHOT_LOG = LOG_ROOT / "snapshot.jsonl"
CHANGED_LOG = LOG_ROOT / "changed_files.jsonl"
DELETED_LOG = LOG_ROOT / "deleted.jsonl"

# === é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ ===
EXCLUDE_KEYWORDS = (
    ".DS_Store", "._", "_DAV", "@eaDir", "$RECYCLE.BIN",
    ".Trash", ".Recycle", "Thumbs.db"
)

# === å¯¾è±¡æ‹¡å¼µå­ ===
VALID_EXTS = (".doc", ".docx", ".rtf", ".pdf", ".xls", ".xlsx", ".json")

def is_excluded(path: Path) -> bool:
    """ã‚´ãƒŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ»éš ã—ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»å¯¾è±¡å¤–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–"""
    if any(part.startswith(".") for part in path.parts):
        return True
    if any(keyword in part for part in path.parts for keyword in EXCLUDE_KEYWORDS):
        return True
    if path.suffix.lower() not in VALID_EXTS:
        return True
    return False

def load_snapshot(path: Path) -> dict:
    """æ—¢å­˜ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    if not path.exists():
        return {}
    snapshot = {}
    for entry in read_jsonl(path):
        snapshot[entry["rel_path"]] = (entry["mtime"], entry["size"])
    return snapshot

def build_current_snapshot(nas_root: Path) -> dict:
    """ç¾åœ¨ã®NASçŠ¶æ…‹ã‚’å–å¾—"""
    snapshot = {}
    for file in nas_root.rglob("*"):
        if not file.is_file():
            continue
        if is_excluded(file):
            continue
        try:
            stat = file.stat()
            snapshot[file.relative_to(nas_root).as_posix()] = (stat.st_mtime, stat.st_size)
        except Exception as e:
            print(f"[WARN] ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå–å¾—å¤±æ•—: {file} ({e})")
    return snapshot

def compare_snapshots(old: dict, new: dict):
    """ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå·®åˆ†æ¯”è¼ƒï¼ˆæ›´æ–°ã¯å‰Šé™¤+æ–°è¦æ‰±ã„ï¼‰"""
    changed, deleted = [], []
    for rel_path, (mtime, size) in new.items():
        if rel_path not in old:
            # âœ… æ–°è¦è¿½åŠ 
            changed.append({"rel_path": rel_path, "mtime": mtime, "size": size})
        elif old[rel_path] != (mtime, size):
            # âœ… æ›´æ–°æ‰±ã„ â†’ æ—§ãƒ‡ãƒ¼ã‚¿ã¯å‰Šé™¤ã€æ–°ãƒ‡ãƒ¼ã‚¿ã¯æ–°è¦
            deleted.append({
                "rel_path": rel_path,
                "mtime": old[rel_path][0],
                "size": old[rel_path][1]
            })
            changed.append({"rel_path": rel_path, "mtime": mtime, "size": size})
    for rel_path in old:
        if rel_path not in new:
            deleted.append({
                "rel_path": rel_path,
                "mtime": old[rel_path][0],
                "size": old[rel_path][1]
            })
    return changed, deleted

# === ãƒ¡ã‚¤ãƒ³ ===
def main():
    print("â–¶ï¸ detect_changes.py é–‹å§‹ï¼ˆã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜å‰Šé™¤ç‰ˆãƒ»æ›´æ–°=å‰Šé™¤æ‰±ã„æ”¹ä¿®ï¼‰")

    NAS_ROOT = Path("/mydata/nas")

    old_snapshot = load_snapshot(SNAPSHOT_LOG)
    current_snapshot = build_current_snapshot(NAS_ROOT)

    changed, deleted = compare_snapshots(old_snapshot, current_snapshot)

    write_jsonl_atomic_sync(CHANGED_LOG, changed)
    write_jsonl_atomic_sync(DELETED_LOG, deleted)

    # âŒ save_snapshot(current_snapshot, SNAPSHOT_LOG) ã¯å‰Šé™¤ï¼ˆæ—¢å­˜ä»•æ§˜ç¶­æŒï¼‰

    print(f"[RESULT] âœ… æ›´æ–°ãƒ»æ–°è¦: {len(changed)} ä»¶, ğŸ—‘ å‰Šé™¤: {len(deleted)} ä»¶")
    print("âœ… detect_changes.py å®Œäº†")

if __name__ == "__main__":
    main()





























