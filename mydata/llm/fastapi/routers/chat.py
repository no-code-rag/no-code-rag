# chat.py
import os
import json
import httpx
import asyncio
import logging
import re
from pathlib import Path
from typing import List
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from .chat_room import save_streamed_message

router = APIRouter(prefix="/v1/chat")
logging.basicConfig(level=logging.INFO)

LLM_HOST = os.getenv("LLM_HOST", "http://llama:8000")
SEARCH_API_URL = "http://vector:8000/embed_search"
PROMPT_DIR = Path("/mydata/llm/fastapi/config/prompts")
RAG_PROMPT_DIR = Path("/mydata/llm/fastapi/config/rag_prompt")

class Message(BaseModel):
    role: str
    content: str
    model: str = ""
    speaker_uuid: str = ""
    style_id: int = 0
    room_id: str = ""

class CompletionRequest(BaseModel):
    model: str
    messages: List[Message]
    stream: bool = True
    speaker_uuid: str = ""
    style_id: int = 0
    room_id: str = ""
    prompt_id: str = "rag_default"
    rag_mode: str = "use"

def load_prompt_text(path: Path) -> str:
    if not path.exists():
        return ""
    lines = path.read_text(encoding="utf-8").splitlines()
    return "\n".join(lines[1:]).strip() if len(lines) > 1 else ""

def load_base_prompt(prompt_id: str) -> str:
    path = PROMPT_DIR / f"{prompt_id}.txt"
    if not path.exists():
        path = PROMPT_DIR / "rag_default.txt"
    return load_prompt_text(path)

def load_rag_instruction(rag_mode: str) -> str:
    path = RAG_PROMPT_DIR / f"{rag_mode}.txt"
    if not path.exists():
        path = RAG_PROMPT_DIR / "use.txt"
    return load_prompt_text(path)

async def extract_keywords(query: str, model: str) -> List[str]:
    try:
        def clean_json_codeblock(text: str) -> str:
            match = re.search(r"```(?:json)?\s*(\[[\s\S]+?\])\s*```", text)
            if match:
                return match.group(1).strip()
            return text.strip()

        payload = {
            "model": model,
            "messages": [
                {
                    "role": "system",
                    "content": (
                        "ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•æ–‡ã«**å®Ÿéš›ã«ç™»å ´ã™ã‚‹åè©ã®ã¿**ã‚’æŠ½å‡ºã—ã€"
                        "æ¤œç´¢ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã—ã¦æœ€å¤§5å€‹ã¾ã§JSONé…åˆ—ã§è¿”ã™ã“ã¨ã§ã™ã€‚\n\n"
                        "ğŸ”’åˆ¶ç´„æ¡ä»¶ï¼š\n"
                        "- å‡ºåŠ›ã™ã‚‹å˜èªã¯ã€å…¥åŠ›æ–‡ã«**å®Ÿéš›ã«ç¾ã‚ŒãŸåè©**ã®ã¿ã¨ã™ã‚‹ã“ã¨ï¼ˆè¨€ã„æ›ãˆãƒ»é¡ç¾©èªã¯ç¦æ­¢ï¼‰\n"
                        "- åè©ä»¥å¤–ï¼ˆå‹•è©ãƒ»å½¢å®¹è©ãƒ»å‰¯è©ãªã©ï¼‰ã¯å«ã‚ãªã„\n"
                        "- æŠ½è±¡èªãƒ»æ±ç”¨èªï¼ˆä¾‹ï¼šäº‹æ¡ˆã€å•é¡Œã€ã‚±ãƒ¼ã‚¹ã€å†…å®¹ ãªã©ï¼‰ã¯å«ã‚ãªã„\n"
                        "- å˜èªã®é †ç•ªã¯ã€æ–‡ä¸­ã®å‡ºç¾é †ã¨ä¸€è‡´ã•ã›ã¦ãã ã•ã„\n"
                        "- å‡ºåŠ›ã¯JSONé…åˆ—ã®ã¿ã€‚ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ```ï¼‰ã‚„èª¬æ˜ã¯ç¦æ­¢\n\n"
                        "âœ…è‰¯ã„ä¾‹ï¼š\n"
                        "å…¥åŠ›ï¼šæ­»åˆ‘åˆ¤æ±ºãŒå‡ºã•ã‚ŒãŸã‚±ãƒ¼ã‚¹ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„\n"
                        "å‡ºåŠ›ï¼š[\"æ­»åˆ‘åˆ¤æ±º\"]\n\n"
                        "âŒæ‚ªã„ä¾‹ï¼š\n"
                        "[\"å†¤ç½ª\"] â† æ–‡ä¸­ã«å­˜åœ¨ã—ãªã„\n"
                        "[\"åˆ‘ç½°\", \"åˆ¤ä¾‹\"] â† é¡ç¾©èª\n"
                        "```[\"æ­»åˆ‘\"]``` â† ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯ç¦æ­¢\n"
                    )
                },
                {
                    "role": "user",
                    "content": f"è³ªå•ï¼šã€Œ{query}ã€"
                },
            ],
        }

        async with httpx.AsyncClient() as client:
            res = await client.post(f"{LLM_HOST}/v1/chat/completions", json=payload, timeout=20)
            res.raise_for_status()

            content_raw = res.json()["choices"][0]["message"]["content"]
            content = clean_json_codeblock(content_raw)

            if not content or not content.startswith("["):
                logging.warning(f"[WARN] keywordæŠ½å‡º å¿œç­”å½¢å¼ç•°å¸¸: {content_raw}")
                return []

            return json.loads(content)

    except Exception as e:
        logging.warning(f"[WARN] keywordæŠ½å‡ºå¤±æ•—: {e}")
        return []

@router.post("/completions")
async def completions(req: CompletionRequest):
    user_message = next((m.content for m in reversed(req.messages) if m.role == "user"), "")
    if not user_message:
        raise HTTPException(status_code=400, detail="ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“")

    if req.room_id:
        save_streamed_message(req.room_id, role="user", content=user_message, model=req.model)

    character_raw = load_base_prompt(req.prompt_id).strip()
    rag_template_raw = load_rag_instruction(req.rag_mode)
    if "{context_text}" not in rag_template_raw:
        rag_template_raw += "\n\nã€RAGãƒãƒ£ãƒ³ã‚¯ã€‘\n{context_text}"

    context_text = ""
    if req.rag_mode != "off":
        keywords = await extract_keywords(user_message, req.model)
        logging.info(f"[INFO] ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºçµæœï¼ˆ{len(keywords)}ä»¶ï¼‰: {', '.join(keywords)}")
        try:
            async with httpx.AsyncClient() as client:
                res = await client.post(SEARCH_API_URL, json={
                    "query": user_message,
                    "keywords": keywords,
                    "top_k": 50
                })
                res.raise_for_status()
                context_text = res.json().get("context_text", "")
                logging.info(f"[RAGãƒãƒ£ãƒ³ã‚¯å…ˆé ­500æ–‡å­—]\n{context_text[:500]}")
        except Exception as e:
            logging.warning(f"[WARN] context_textå–å¾—å¤±æ•—: {e}")
            context_text = ""

    rag_filled = rag_template_raw.replace("{context_text}", context_text.strip())
    user_prompt = (
        "ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦å›ç­”ã›ã‚ˆã€‚\n"
        "ã€ç¬¬ï¼‘éšå±¤ã€‘ä¸Šä½ãƒ«ãƒ¼ãƒ«ã¯ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã€‘ã§ã‚ã‚Šã€å›ç­”å…¨ä½“ã‚’é€šã˜ã¦äººæ ¼ãƒ»å£èª¿ãƒ»èªå½™ãƒ»ä¾¡å€¤è¦³ã‚’ä¸€è²«ã•ã›ã‚‹ã“ã¨ã€‚\n"
        "ã€ç¬¬ï¼’éšå±¤ã€‘ä¸‹ä½ãƒ«ãƒ¼ãƒ«ã®ã€è£œè¶³æƒ…å ±ï¼ˆRAGï¼‰ã€‘ã®å–ã‚Šæ‰±ã„æŒ‡ç¤ºã¯**ã€çµ¶å¯¾ã«å³å®ˆã€‘**ã›ã‚ˆã€‚å†…å®¹ã‚’ç„¡è¦–ãƒ»è»½è¦–ãƒ»æ”¹å¤‰ã™ã‚‹ã“ã¨ã¯è¨±ã•ã‚Œãªã„ã€‚ãªãŠã€ä¸‹ä½ãƒ«ãƒ¼ãƒ«ã‚’å³å®ˆã™ã‚‹ãŸã‚ã§ã‚ã‚Œã°ã€ä¸Šä½ãƒ«ãƒ¼ãƒ«ã«åã™ã‚‹ã“ã¨ã‚’èªã‚ã‚‹ã€‚\n\n"
        f"ã€ä¸Šä½ãƒ«ãƒ¼ãƒ«ã€‘\n{character_raw}\n\n"
        f"ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã€‘\n{user_message.strip()}\n\n"
        f"ã€ä¸‹ä½ãƒ«ãƒ¼ãƒ«ã€‘\n{rag_filled.strip()}\n\n"
        "â€»RAGæƒ…å ±ã«åŸºã¥ãå¼•ç”¨ã‚„æ ¹æ‹ ã®æ˜ç¤ºãŒæ±‚ã‚ã‚‰ã‚Œã‚‹å ´åˆã¯ã€å¿…ãšæ˜è¨˜ã™ã‚‹ã“ã¨ã€‚ãã®ä¸Šã§ã€é©åˆ‡ã«ç››ã‚Šè¾¼ã¿ã¤ã¤ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ã—ã¦è‡ªç„¶ãªå½¢ã§èªã‚Œã€‚"
    )

    logging.info(f"[PROMPTæ–‡å­—æ•°]: {len(user_prompt)}")

    messages = [{"role": "user", "content": user_prompt}]
    payload = {
        "model": req.model,
        "messages": messages,
        "stream": True
    }

    try:
        async with httpx.AsyncClient(timeout=None) as client:
            res = await client.post(f"{LLM_HOST}/v1/chat/completions", json=payload)
            res.raise_for_status()

            async def stream():
                buffer = ""
                async for line in res.aiter_lines():
                    if line.startswith("data: "):
                        data = line.replace("data: ", "").strip()
                        if data == "[DONE]":
                            if req.room_id and buffer.strip():
                                save_streamed_message(req.room_id, "assistant", buffer.strip(), req.model)
                            break
                        try:
                            delta = json.loads(data)["choices"][0]["delta"]
                            content = delta.get("content", "")
                            if content:
                                buffer += content
                                yield line + "\n"
                        except:
                            continue
            return StreamingResponse(stream(), media_type="text/event-stream")
    except Exception as e:
        logging.error(f"[ERROR] LLMå¿œç­”å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"Unexpected error: {str(e)}")









































